<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-10-18T17:16:10+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">msaidov.com</title><subtitle></subtitle><author><name>Marat Saidov</name><email>marat.a.saidov@gmail.com</email></author><entry><title type="html">A Large Language Model That Can Speak And Listen</title><link href="http://localhost:4000/audio-palm-survey/" rel="alternate" type="text/html" title="A Large Language Model That Can Speak And Listen" /><published>2023-07-12T00:00:00+02:00</published><updated>2023-07-12T00:00:00+02:00</updated><id>http://localhost:4000/a-large-language-model-that-can-speak-and-listen</id><content type="html" xml:base="http://localhost:4000/audio-palm-survey/"><![CDATA[<p>AudioPaLM: A Large Language Model That Can Speak and Listen.</p>

<p>It has been a month since the release of the novel speech processing model called AudioPaLM. In this survey I try to explain the frontier of the speech signal processing addressing AudioPaLM as an example:</p>

<ul>
  <li>How transformers capture the textual and speech data without a significant loss in quality;</li>
  <li>Which parts of the study are potentially useful when it is necessary to implement / fine-tune custom speech neural models, i.e. on the specific tasks such as Automatic Speech Recognition (ASR) or Voice Quality Enhancement (VQE).</li>
</ul>

<p><br /></p>]]></content><author><name>Marat Saidov</name><email>marat.a.saidov@gmail.com</email></author><summary type="html"><![CDATA[AudioPaLM: A Large Language Model That Can Speak and Listen.]]></summary></entry><entry><title type="html">Asian Journey In 2022</title><link href="http://localhost:4000/asian-journey/" rel="alternate" type="text/html" title="Asian Journey In 2022" /><published>2023-02-10T00:00:00+01:00</published><updated>2023-02-10T00:00:00+01:00</updated><id>http://localhost:4000/asian-journey-in-2022</id><content type="html" xml:base="http://localhost:4000/asian-journey/"><![CDATA[<p>I am fond of the Western attitude towards a gap year.</p>

<p>There exist travel programs for those who have obtained a BSc and wish to take a break before pursuing their MSc. <br />
In my case, the gap year turned out to be involuntary. Furthermore, it extended far beyond a year. Nevertheless, it harmoniously aligned with the Western approach.</p>

<p>I left Russia at the end of September and only found a new home in February. Although I have yet to tackle lengthy posts about each of the countries I had the opportunity to visit, I desire to showcase the route and document this extraordinary journey.</p>

<figure class=" ">
  
    
      <a href="/assets/images/asian-journey-overview.png" title="Route.">
          <img src="/assets/images/asian-journey-overview.png" alt="" />
      </a>
    
  
  
</figure>

<p>Kazakhstan 🇰🇿 -&gt; India 🇮🇳 -&gt; Thailand 🇹🇭 -&gt; Malaysia 🇲🇾 -&gt; Thailand Again 🇹🇭 -&gt; Vietnam 🇻🇳… and finally, Serbia 🇷🇸.</p>

<p>The power of such adventures lies in the everyday challenges. New challenges. Ones that had never arisen before. For instance, how does one mount a scooter if they have never even sat on a bicycle? How does one persuade stern Vietnamese border officials at Saigon airport that I am flying to Serbia not as a tourist, but for a new job awaiting me there?</p>

<p>It was truly fascinating. I will never replicate anything similar.</p>]]></content><author><name>Marat Saidov</name><email>marat.a.saidov@gmail.com</email></author><summary type="html"><![CDATA[I am fond of the Western attitude towards a gap year.]]></summary></entry><entry><title type="html">The Rps Race</title><link href="http://localhost:4000/the-rps-race/" rel="alternate" type="text/html" title="The Rps Race" /><published>2022-11-14T00:00:00+01:00</published><updated>2022-11-14T00:00:00+01:00</updated><id>http://localhost:4000/the-RPS-race</id><content type="html" xml:base="http://localhost:4000/the-rps-race/"><![CDATA[<p>The MVP for a model serving cloud-native solution.</p>

<p>At my previous role, we actively set up a production environment for deploying hundreds of machine learning models. I want to talk about the central metric in this task - RPS (requests per second) - and the first step taken to improve it.</p>

<p>Typically, RPS is associated with Site Reliability Engineering. Often, it involves web services with heavy backends, sprawling databases, and a large pool of users. For example, the SRE team at Google recently exceeded 3,500 people. <a href="https://sre.google/">Ben Treynor, VP of SRE at Google, explains</a>: “Typically, we hire about a 50-50 mix of people who have more of a software background and people who have more of a systems engineering background. It seems to be a really good mix.”</p>

<p>In the field of machine learning, I would highlight some preliminary knowledge required for developing such an ML environment:</p>

<ul>
  <li>DevOps and infrastructure development;</li>
  <li>Building end-to-end ML pipelines: from data preprocessing and feature selection to parameter tuning;</li>
  <li>Understanding the open-source world of model deployment and how to leverage it to avoid reinventing the wheel.</li>
</ul>

<p>Ultimately, it becomes a mix of hardcore engineering, non-trivial analytics, and system design. It sounds inspiring until you start measuring the system’s performance.</p>

<p>🐌 RPS = 21</p>

<p>In its most basic version, we achieved 21 requests per second, or a minute-long wait for a response under a load of around 1200 users. Unacceptable. We need to identify the bottleneck.</p>

<p>In the image below, the folks at MLflow propose a model storage architecture. AWS S3 is used for storing the weights. However, data transfer occurs over the network (a.k.a. slowly).</p>

<figure class=" ">
  
    
      <a href="/assets/images/mlflow.jpg" title="MLflow model registry including S3 bucket.">
          <img src="/assets/images/mlflow.jpg" alt="" />
      </a>
    
  
  
    <figcaption>Source: https://mlflow.org/docs/latest/model-registry.html
</figcaption>
  
</figure>

<p>It was noticed that the model weights were being transmitted over the network with every request to the environment, which was a severe bottleneck. Let’s keep the models in RAM after the initial transfer.</p>

<p>🏃‍♂️ RPS = 155</p>

<p>A simple heuristic, yet the acceleration is more than sevenfold. In the end, through a trade-off between memory and speed, we achieved acceptable system performance for the first version of the product. This means we can proudly call ourselves MLOps engineers.</p>]]></content><author><name>Marat Saidov</name><email>marat.a.saidov@gmail.com</email></author><summary type="html"><![CDATA[The MVP for a model serving cloud-native solution.]]></summary></entry></feed>